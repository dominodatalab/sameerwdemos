{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e71764e-d63c-4e1d-a04a-f83694dd2df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/mnt/code/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47d86df3-4c72-4f0a-a886-c56ce9c2b0a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-04 12:07:31.341616: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 12:07:31.385730: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 12:07:31.385764: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 12:07:31.387028: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 12:07:31.394104: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 12:07:31.394609: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 12:07:32.300832: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-04 12:07:33,383\tINFO util.py:154 -- Outdated packages:\n",
      "  ipywidgets==7.7.5 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-03-04 12:07:33,466\tINFO util.py:154 -- Outdated packages:\n",
      "  ipywidgets==7.7.5 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-03-04 12:07:33,556\tINFO util.py:154 -- Outdated packages:\n",
      "  ipywidgets==7.7.5 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import mlflow\n",
    "import tensorflow\n",
    "from filelock import FileLock\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "import ray\n",
    "from ray import train, tune\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "from ray.air.integrations.keras import ReportCheckpointCallback\n",
    "from domino_mlflow_utils.mlflow_utilities import DominoMLflowUtilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6f444f2-4b23-4a0b-8e6f-bf401d181c50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "/mnt/data/mlflow-demos/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-04 12:07:33,803\tINFO packaging.py:530 -- Creating a file package for local directory '/mnt/code/domino_mlflow_utils'.\n",
      "2024-03-04 12:07:33,806\tINFO packaging.py:358 -- Pushing file package 'gcs://_ray_pkg_4a7195b3dc02649b.zip' (0.07MiB) to Ray cluster...\n",
      "2024-03-04 12:07:33,808\tINFO packaging.py:371 -- Successfully pushed file package 'gcs://_ray_pkg_4a7195b3dc02649b.zip'.\n",
      "SIGTERM handler is not set because current thread is not the main thread.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray Initializied\n",
      "Ray Host=ray-65e5b5c446b29e1208590160-ray-client.domino-compute.svc.cluster.local and Ray Port=10001\n"
     ]
    }
   ],
   "source": [
    "service_host = os.environ[\"RAY_HEAD_SERVICE_HOST\"]\n",
    "service_port = os.environ[\"RAY_HEAD_SERVICE_PORT\"]\n",
    "print(ray.is_initialized())\n",
    "\n",
    "if not ray.is_initialized():\n",
    "\n",
    "    address=f\"ray://{service_host}:{service_port}\"\n",
    "    temp_dir='/mnt/data/{}/'.format(os.environ['DOMINO_PROJECT_NAME']) #set to a dataset\n",
    "    print(temp_dir)\n",
    "    ray.init(address=address, _temp_dir=temp_dir, runtime_env={\"py_modules\": ['/mnt/code/domino_mlflow_utils']})\n",
    "\n",
    "print('Ray Initializied')\n",
    "print(f'Ray Host={service_host} and Ray Port={service_port}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2b76036-45ed-483f-b249-7a7828d3a24b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAY-TUNE-KERAS-integration-test-mlflow-demos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/mlflow', creation_time=1709553471949, experiment_id='11', last_update_time=1709553471949, lifecycle_stage='active', name='RAY-TUNE-KERAS-integration-test-mlflow-demos', tags={'mlflow.domino.dataset_info': '65e5557b90758361e5bc3492-65e5557b90758361e5bc3491',\n",
       " 'mlflow.domino.environment_id': '65e5738090758361e5bc34aa',\n",
       " 'mlflow.domino.environment_revision_id': '65e5aedb90758361e5bc353c',\n",
       " 'mlflow.domino.hardware_tier': 'small-k8s',\n",
       " 'mlflow.domino.project_id': '65e5557490758361e5bc348d',\n",
       " 'mlflow.domino.project_name': 'mlflow-demos',\n",
       " 'mlflow.domino.run_id': '65e5b5c446b29e1208590160',\n",
       " 'mlflow.domino.run_number': '6',\n",
       " 'mlflow.domino.user': 'integration-test',\n",
       " 'mlflow.domino.user_id': '65df309894ef6c5ddd8b2705',\n",
       " 'mlflow.source.type': 'NOTEBOOK',\n",
       " 'mlflow.user': 'integration-test'}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name = 'RAY-TUNE-KERAS'+'-' + os.environ['DOMINO_STARTING_USERNAME'] + '-' + os.environ['DOMINO_PROJECT_NAME']\n",
    "mlflow_tracking_uri = os.environ['CLUSTER_MLFLOW_TRACKING_URI']\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "experiment = client.get_experiment_by_name(name=experiment_name)\n",
    "if(experiment is None):\n",
    "    print('Creating experiment ')\n",
    "    client.create_experiment(name=experiment_name)\n",
    "    experiment = client.get_experiment_by_name(name=experiment_name)\n",
    "\n",
    "print(experiment_name)\n",
    "mlflow.set_experiment(experiment_name=experiment_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4c81821-8b4f-4f32-b261-323da3c483b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ray.air._internal.mlflow import _MLflowLoggerUtil\n",
    "mlflow_util = _MLflowLoggerUtil()\n",
    "def initialize_run():    \n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    mlflow_tracking_uri = os.environ['CLUSTER_MLFLOW_TRACKING_URI']\n",
    "\n",
    "    mlflow_util.setup_mlflow(\n",
    "            tracking_uri=mlflow_tracking_uri,            \n",
    "            experiment_name=experiment_name,\n",
    "        )\n",
    "    now = round(time.time())\n",
    "    now_str=time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(now))\n",
    "\n",
    "\n",
    "\n",
    "    mlflow_util.start_run(tags={}, run_name=f\"root-{now_str}\")\n",
    "    return run.info.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a86210d2-b6c9-4e08-b6e4-de5ac860bd03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "temp_dir='/mnt/data/{}/'.format(os.environ['DOMINO_PROJECT_NAME']) #set to a dataset\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "mlflow_tracking_uri = os.environ['CLUSTER_MLFLOW_TRACKING_URI']\n",
    "\n",
    "def train_mnist(config):\n",
    "    # https://github.com/tensorflow/tensorflow/issues/32159\n",
    "    \n",
    "\n",
    "    batch_size = 128\n",
    "    num_classes = 10\n",
    "    epochs = 12\n",
    "    parent_run_id = config['parent_run_id']\n",
    "\n",
    "    with FileLock(os.path.expanduser(\"~/.data.lock\")):\n",
    "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            tf.keras.layers.Dense(config[\"hidden\"], activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        optimizer=tf.keras.optimizers.SGD(lr=config[\"lr\"], momentum=config[\"momentum\"]),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    #cb = ReportCheckpointCallback2(metrics={\"mean_accuracy\": \"accuracy\"})\n",
    "    \n",
    "    mlflow.tensorflow.autolog()\n",
    "    run_tags={}\n",
    "    run_tags[\"mlflow.parentRunId\"] = parent_run_id\n",
    "    mlflow_utils = DominoMLflowUtilities()    \n",
    "    mlflow_utils.init(experiment_name,config,run_tags=run_tags)\n",
    "\n",
    "    model.fit(\n",
    "            x_train,\n",
    "            y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=0,\n",
    "            validation_data=(x_test, y_test),\n",
    "            callbacks=[ReportCheckpointCallback(metrics={\"mean_accuracy\": \"accuracy\"})],\n",
    "        )\n",
    "    mlflow_utils.finish()\n",
    "\n",
    "\n",
    "def tune_mnist(parent_run_id):\n",
    "    sched = AsyncHyperBandScheduler(\n",
    "        time_attr=\"training_iteration\", max_t=400, grace_period=20\n",
    "    )\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(train_mnist, resources={\"cpu\": 1, \"gpu\": 0}),\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"mean_accuracy\",\n",
    "            mode=\"max\",\n",
    "            scheduler=sched,\n",
    "            num_samples=10,            \n",
    "        ),\n",
    "        run_config=train.RunConfig(\n",
    "            name=\"exp\",\n",
    "            stop={\"mean_accuracy\": 0.99},\n",
    "            storage_path=temp_dir,\n",
    "        ),\n",
    "        param_space={\n",
    "            \"threads\": 2,\n",
    "            \"lr\": tune.uniform(0.001, 0.1),\n",
    "            \"momentum\": tune.uniform(0.1, 0.9),\n",
    "            \"hidden\": tune.randint(32, 512),\n",
    "            \"parent_run_id\": parent_run_id\n",
    "        },\n",
    "    )\n",
    "    results = tuner.fit()\n",
    "    \n",
    "    print(\"Best hyperparameters found were: \", results.get_best_result().config)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "267363c7-103f-4eae-8d2e-379de6762220",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m [output] This will use the new output engine with verbosity 1. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╭──────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ Configuration for experiment     exp                     │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ├──────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ Search algorithm                 BasicVariantGenerator   │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ Scheduler                        AsyncHyperBandScheduler │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ Number of trials                 10                      │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╰──────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m View detailed results here: /mnt/data/mlflow-demos/exp\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m To visualize your results with TensorBoard, run: `tensorboard --logdir /home/ray/ray_results/exp`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m AIR_VERBOSITY is set, ignoring passed-in ProgressReporter for now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Trial status: 10 PENDING\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Current time: 2024-03-04 04:07:47. Total running time: 0s\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Logical resource usage: 0/4 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╭─────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ Trial name                status             lr     momentum     hidden │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ├─────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00000   PENDING    0.0986987      0.112969         89 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00001   PENDING    0.0351482      0.585167         64 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00002   PENDING    0.0474651      0.123255         91 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00003   PENDING    0.0353766      0.49207         440 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00004   PENDING    0.0719952      0.55623         496 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00005   PENDING    0.0388087      0.123387        505 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00006   PENDING    0.0747164      0.44443         429 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00007   PENDING    0.017199       0.513358        484 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00008   PENDING    0.0109866      0.126216        141 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00009   PENDING    0.00986737     0.645657         83 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╰─────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(pid=744, ip=100.64.7.88)\u001b[0m 2024-03-04 04:07:50.168710: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "\u001b[36m(pid=744, ip=100.64.7.88)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=386, ip=100.64.67.193)\u001b[0m 2024-03-04 04:07:50.179679: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "\u001b[36m(pid=386, ip=100.64.67.193)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=851, ip=100.64.11.148)\u001b[0m 2024-03-04 04:07:50.382555: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "\u001b[36m(pid=851, ip=100.64.11.148)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=2133)\u001b[0m 2024-03-04 04:07:51.092856: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "\u001b[36m(pid=2133)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=744, ip=100.64.7.88)\u001b[0m 2024-03-04 04:07:51.150660: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[36m(pid=744, ip=100.64.7.88)\u001b[0m 2024-03-04 04:07:51.150727: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[36m(pid=744, ip=100.64.7.88)\u001b[0m 2024-03-04 04:07:51.150733: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001b[36m(pid=386, ip=100.64.67.193)\u001b[0m 2024-03-04 04:07:51.139266: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[36m(pid=386, ip=100.64.67.193)\u001b[0m 2024-03-04 04:07:51.139330: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[36m(pid=386, ip=100.64.67.193)\u001b[0m 2024-03-04 04:07:51.139336: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001b[36m(pid=851, ip=100.64.11.148)\u001b[0m 2024-03-04 04:07:51.451790: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[36m(pid=851, ip=100.64.11.148)\u001b[0m 2024-03-04 04:07:51.451866: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[36m(pid=851, ip=100.64.11.148)\u001b[0m 2024-03-04 04:07:51.451873: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001b[36m(pid=2133)\u001b[0m 2024-03-04 04:07:52.340378: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[36m(pid=2133)\u001b[0m 2024-03-04 04:07:52.340447: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[36m(pid=2133)\u001b[0m 2024-03-04 04:07:52.340453: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Trial train_mnist_ceeae_00000 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ Trial train_mnist_ceeae_00000 config                          │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ hidden                                                     89 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ lr                                                     0.0987 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ momentum                                              0.11297 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ parent_run_id                            ...3946a937639f9933f │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ threads                                                     2 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Trial train_mnist_ceeae_00001 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ Trial train_mnist_ceeae_00001 config                          │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ hidden                                                     64 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ lr                                                    0.03515 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ momentum                                              0.58517 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ parent_run_id                            ...3946a937639f9933f │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ threads                                                     2 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Trial train_mnist_ceeae_00002 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ Trial train_mnist_ceeae_00002 config                          │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ hidden                                                     91 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ lr                                                    0.04747 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ momentum                                              0.12326 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ parent_run_id                            ...3946a937639f9933f │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ threads                                                     2 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checking for active runs, Active Run= None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m 2024-03-04 04:07:53.246252: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m 2024-03-04 04:07:53.246284: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m 2024-03-04 04:07:53.249286: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m 2024-03-04 04:07:53.249315: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checking for active runs, Active Run= None\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Started new run with run_id: d76f8930c8b5434c86bf7a4f6b8a313b\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m {'threads': 2, 'lr': 0.03514824693788851, 'momentum': 0.5851673239675689, 'hidden': 64, 'parent_run_id': 'e836dcb261914663946a937639f9933f'}\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Started new run with run_id: 5f231290da3f4ebaa81f877818a36592\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m {'threads': 2, 'lr': 0.09869868662947145, 'momentum': 0.11296900067787297, 'hidden': 89, 'parent_run_id': 'e836dcb261914663946a937639f9933f'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m 2024-03-04 04:07:53.736305: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m 2024-03-04 04:07:53.736335: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m Checking for active runs, Active Run= None\n",
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m Started new run with run_id: 7bebdf9e81564875878c8bbe8b60fff4\n",
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m {'threads': 2, 'lr': 0.047465097819278906, 'momentum': 0.12325535845953164, 'hidden': 91, 'parent_run_id': 'e836dcb261914663946a937639f9933f'}\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Trial train_mnist_ceeae_00003 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ Trial train_mnist_ceeae_00003 config                          │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ hidden                                                    440 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ lr                                                    0.03538 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ momentum                                              0.49207 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ parent_run_id                            ...3946a937639f9933f │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ threads                                                     2 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=2133)\u001b[0m 2024-03-04 04:07:55.302566: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[36m(train_mnist pid=2133)\u001b[0m 2024-03-04 04:07:55.302595: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "\u001b[36m(train_mnist pid=2133)\u001b[0m WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=2133)\u001b[0m Checking for active runs, Active Run= None\n",
      "\u001b[36m(train_mnist pid=2133)\u001b[0m Started new run with run_id: 90316abe10ad4c0ab4c88a8c39529fe0\n",
      "\u001b[36m(train_mnist pid=2133)\u001b[0m {'threads': 2, 'lr': 0.03537662731344751, 'momentum': 0.49206975635349515, 'hidden': 440, 'parent_run_id': 'e836dcb261914663946a937639f9933f'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0018s vs `on_train_batch_end` time: 0.0037s). Check your callbacks.\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0018s vs `on_train_batch_end` time: 0.0037s). Check your callbacks.\n",
      "\u001b[36m(train_mnist pid=2133)\u001b[0m 2024-03-04 04:07:57.327708: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 188160000 exceeds 10% of free system memory.\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00000_0_hidden=89,lr=0.0987,momentum=0.1130_2024-03-04_04-07-47/checkpoint_000000)\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00001_1_hidden=64,lr=0.0351,momentum=0.5852_2024-03-04_04-07-47/checkpoint_000000)\n",
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00002_2_hidden=91,lr=0.0475,momentum=0.1233_2024-03-04_04-07-47/checkpoint_000000)\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00000_0_hidden=89,lr=0.0987,momentum=0.1130_2024-03-04_04-07-47/checkpoint_000001)\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00001_1_hidden=64,lr=0.0351,momentum=0.5852_2024-03-04_04-07-47/checkpoint_000001)\n",
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00002_2_hidden=91,lr=0.0475,momentum=0.1233_2024-03-04_04-07-47/checkpoint_000001)\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00001_1_hidden=64,lr=0.0351,momentum=0.5852_2024-03-04_04-07-47/checkpoint_000002)\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00000_0_hidden=89,lr=0.0987,momentum=0.1130_2024-03-04_04-07-47/checkpoint_000002)\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00001_1_hidden=64,lr=0.0351,momentum=0.5852_2024-03-04_04-07-47/checkpoint_000003)\n",
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00002_2_hidden=91,lr=0.0475,momentum=0.1233_2024-03-04_04-07-47/checkpoint_000002)\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00000_0_hidden=89,lr=0.0987,momentum=0.1130_2024-03-04_04-07-47/checkpoint_000003)\n",
      "\u001b[36m(train_mnist pid=2133)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00003_3_hidden=440,lr=0.0354,momentum=0.4921_2024-03-04_04-07-47/checkpoint_000000)\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00001_1_hidden=64,lr=0.0351,momentum=0.5852_2024-03-04_04-07-47/checkpoint_000004)\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00000_0_hidden=89,lr=0.0987,momentum=0.1130_2024-03-04_04-07-47/checkpoint_000004)\n",
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00002_2_hidden=91,lr=0.0475,momentum=0.1233_2024-03-04_04-07-47/checkpoint_000003)\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00001_1_hidden=64,lr=0.0351,momentum=0.5852_2024-03-04_04-07-47/checkpoint_000005)\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00000_0_hidden=89,lr=0.0987,momentum=0.1130_2024-03-04_04-07-47/checkpoint_000005)\n",
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00002_2_hidden=91,lr=0.0475,momentum=0.1233_2024-03-04_04-07-47/checkpoint_000004)\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00001_1_hidden=64,lr=0.0351,momentum=0.5852_2024-03-04_04-07-47/checkpoint_000006)\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00000_0_hidden=89,lr=0.0987,momentum=0.1130_2024-03-04_04-07-47/checkpoint_000006)\n",
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00002_2_hidden=91,lr=0.0475,momentum=0.1233_2024-03-04_04-07-47/checkpoint_000005)\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00001_1_hidden=64,lr=0.0351,momentum=0.5852_2024-03-04_04-07-47/checkpoint_000007)\n",
      "\u001b[36m(train_mnist pid=2133)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00003_3_hidden=440,lr=0.0354,momentum=0.4921_2024-03-04_04-07-47/checkpoint_000001)\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00000_0_hidden=89,lr=0.0987,momentum=0.1130_2024-03-04_04-07-47/checkpoint_000007)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Trial status: 4 RUNNING | 6 PENDING\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Current time: 2024-03-04 04:08:17. Total running time: 30s\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Logical resource usage: 4.0/4 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Current best trial: ceeae_00001 with mean_accuracy=0.9164333343505859 and params={'threads': 2, 'lr': 0.03514824693788851, 'momentum': 0.5851673239675689, 'hidden': 64, 'parent_run_id': 'e836dcb261914663946a937639f9933f'}\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ Trial name                status             lr     momentum     hidden        acc     iter     total time (s) │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ├────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00000   RUNNING    0.0986987      0.112969         89   0.898767        8            23.6922 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00001   RUNNING    0.0351482      0.585167         64   0.916433        8            22.6174 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00002   RUNNING    0.0474651      0.123255         91   0.892933        6            21.9444 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00003   RUNNING    0.0353766      0.49207         440   0.88215         2            21.4626 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00004   PENDING    0.0719952      0.55623         496                                        │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00005   PENDING    0.0388087      0.123387        505                                        │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00006   PENDING    0.0747164      0.44443         429                                        │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00007   PENDING    0.017199       0.513358        484                                        │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00008   PENDING    0.0109866      0.126216        141                                        │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00009   PENDING    0.00986737     0.645657         83                                        │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00001_1_hidden=64,lr=0.0351,momentum=0.5852_2024-03-04_04-07-47/checkpoint_000008)\n",
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00002_2_hidden=91,lr=0.0475,momentum=0.1233_2024-03-04_04-07-47/checkpoint_000006)\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00000_0_hidden=89,lr=0.0987,momentum=0.1130_2024-03-04_04-07-47/checkpoint_000008)\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00001_1_hidden=64,lr=0.0351,momentum=0.5852_2024-03-04_04-07-47/checkpoint_000009)\n",
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00002_2_hidden=91,lr=0.0475,momentum=0.1233_2024-03-04_04-07-47/checkpoint_000007)\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00000_0_hidden=89,lr=0.0987,momentum=0.1130_2024-03-04_04-07-47/checkpoint_000009)\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00001_1_hidden=64,lr=0.0351,momentum=0.5852_2024-03-04_04-07-47/checkpoint_000010)\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00000_0_hidden=89,lr=0.0987,momentum=0.1130_2024-03-04_04-07-47/checkpoint_000010)\n",
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00002_2_hidden=91,lr=0.0475,momentum=0.1233_2024-03-04_04-07-47/checkpoint_000008)\n",
      "\u001b[36m(train_mnist pid=2133)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00003_3_hidden=440,lr=0.0354,momentum=0.4921_2024-03-04_04-07-47/checkpoint_000002)\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00001_1_hidden=64,lr=0.0351,momentum=0.5852_2024-03-04_04-07-47/checkpoint_000011)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 74ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00000_0_hidden=89,lr=0.0987,momentum=0.1130_2024-03-04_04-07-47/checkpoint_000011)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 100ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00002_2_hidden=91,lr=0.0475,momentum=0.1233_2024-03-04_04-07-47/checkpoint_000009)\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00002_2_hidden=91,lr=0.0475,momentum=0.1233_2024-03-04_04-07-47/checkpoint_000010)\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m 2024/03/04 04:08:31 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ray/anaconda3/lib/python3.9/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n",
      "\u001b[36m(train_mnist pid=2133)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00003_3_hidden=440,lr=0.0354,momentum=0.4921_2024-03-04_04-07-47/checkpoint_000003)\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m 2024/03/04 04:08:32 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ray/anaconda3/lib/python3.9/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n",
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00002_2_hidden=91,lr=0.0475,momentum=0.1233_2024-03-04_04-07-47/checkpoint_000011)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 81ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Trial train_mnist_ceeae_00000 completed after 12 iterations at 2024-03-04 04:08:35. Total running time: 48s\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╭────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ Trial train_mnist_ceeae_00000 result                       │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ├────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ checkpoint_dir_name                      checkpoint_000011 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ time_this_iter_s                                   2.44912 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ time_total_s                                      33.55112 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ training_iteration                                      12 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ mean_accuracy                                      0.91237 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╰────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Trial train_mnist_ceeae_00004 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ Trial train_mnist_ceeae_00004 config                          │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ hidden                                                    496 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ lr                                                      0.072 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ momentum                                              0.55623 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ parent_run_id                            ...3946a937639f9933f │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ threads                                                     2 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m run_id: 5f231290da3f4ebaa81f877818a36592; status: RUNNING\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m --\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m run_id: d76f8930c8b5434c86bf7a4f6b8a313b; status: RUNNING\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m --\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Trial train_mnist_ceeae_00001 completed after 12 iterations at 2024-03-04 04:08:35. Total running time: 48s\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╭────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ Trial train_mnist_ceeae_00001 result                       │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ├────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ checkpoint_dir_name                      checkpoint_000011 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ time_this_iter_s                                   2.32517 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ time_total_s                                      32.00165 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ training_iteration                                      12 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ mean_accuracy                                       0.9278 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╰────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Trial train_mnist_ceeae_00005 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ Trial train_mnist_ceeae_00005 config                          │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ hidden                                                    505 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ lr                                                    0.03881 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ momentum                                              0.12339 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ parent_run_id                            ...3946a937639f9933f │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ threads                                                     2 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checking for active runs, Active Run= None\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Started new run with run_id: bbfdd9371f5344bfae5d55071269fb0b\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m {'threads': 2, 'lr': 0.07199524345173318, 'momentum': 0.5562304366072593, 'hidden': 496, 'parent_run_id': 'e836dcb261914663946a937639f9933f'}\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checking for active runs, Active Run= None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Started new run with run_id: 94e46654ae904f72938b78264bfeaea7\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m {'threads': 2, 'lr': 0.03880869942591415, 'momentum': 0.12338659668623171, 'hidden': 505, 'parent_run_id': 'e836dcb261914663946a937639f9933f'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m 2024/03/04 04:08:40 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ray/anaconda3/lib/python3.9/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n",
      "\u001b[36m(train_mnist pid=2133)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00003_3_hidden=440,lr=0.0354,momentum=0.4921_2024-03-04_04-07-47/checkpoint_000004)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Trial train_mnist_ceeae_00002 completed after 12 iterations at 2024-03-04 04:08:42. Total running time: 55s\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╭────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ Trial train_mnist_ceeae_00002 result                       │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ├────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ checkpoint_dir_name                      checkpoint_000011 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ time_this_iter_s                                   2.88222 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ time_total_s                                      39.52554 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ training_iteration                                      12 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ mean_accuracy                                      0.91487 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╰────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m run_id: 7bebdf9e81564875878c8bbe8b60fff4; status: RUNNING\n",
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m --\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Trial train_mnist_ceeae_00006 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ Trial train_mnist_ceeae_00006 config                          │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ hidden                                                    429 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ lr                                                    0.07472 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ momentum                                              0.44443 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ parent_run_id                            ...3946a937639f9933f │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ threads                                                     2 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m Checking for active runs, Active Run= None\n",
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m Started new run with run_id: 36a82d84abc54ab3a83b26cca59f55c8\n",
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m {'threads': 2, 'lr': 0.074716387366773, 'momentum': 0.44443043656064285, 'hidden': 429, 'parent_run_id': 'e836dcb261914663946a937639f9933f'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00004_4_hidden=496,lr=0.0720,momentum=0.5562_2024-03-04_04-07-47/checkpoint_000000)\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00005_5_hidden=505,lr=0.0388,momentum=0.1234_2024-03-04_04-07-47/checkpoint_000000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Trial status: 3 TERMINATED | 4 RUNNING | 3 PENDING\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Current time: 2024-03-04 04:08:47. Total running time: 1min 0s\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Logical resource usage: 4.0/4 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Current best trial: ceeae_00001 with mean_accuracy=0.9277999997138977 and params={'threads': 2, 'lr': 0.03514824693788851, 'momentum': 0.5851673239675689, 'hidden': 64, 'parent_run_id': 'e836dcb261914663946a937639f9933f'}\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ Trial name                status               lr     momentum     hidden        acc     iter     total time (s) │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00003   RUNNING      0.0353766      0.49207         440   0.915183        5           45.6329  │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00004   RUNNING      0.0719952      0.55623         496   0.791383        1            9.09488 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00005   RUNNING      0.0388087      0.123387        505   0.73265         1            9.56661 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00006   RUNNING      0.0747164      0.44443         429                                        │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00000   TERMINATED   0.0986987      0.112969         89   0.912367       12           33.5511  │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00001   TERMINATED   0.0351482      0.585167         64   0.9278         12           32.0017  │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00002   TERMINATED   0.0474651      0.123255         91   0.914867       12           39.5255  │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00007   PENDING      0.017199       0.513358        484                                        │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00008   PENDING      0.0109866      0.126216        141                                        │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00009   PENDING      0.00986737     0.645657         83                                        │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=2133)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00003_3_hidden=440,lr=0.0354,momentum=0.4921_2024-03-04_04-07-47/checkpoint_000005)\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00004_4_hidden=496,lr=0.0720,momentum=0.5562_2024-03-04_04-07-47/checkpoint_000001)\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00005_5_hidden=505,lr=0.0388,momentum=0.1234_2024-03-04_04-07-47/checkpoint_000001)\n",
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00006_6_hidden=429,lr=0.0747,momentum=0.4444_2024-03-04_04-07-47/checkpoint_000000)\n",
      "\u001b[36m(train_mnist pid=2133)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00003_3_hidden=440,lr=0.0354,momentum=0.4921_2024-03-04_04-07-47/checkpoint_000006)\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00004_4_hidden=496,lr=0.0720,momentum=0.5562_2024-03-04_04-07-47/checkpoint_000002)\n",
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00006_6_hidden=429,lr=0.0747,momentum=0.4444_2024-03-04_04-07-47/checkpoint_000001)\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00005_5_hidden=505,lr=0.0388,momentum=0.1234_2024-03-04_04-07-47/checkpoint_000002)\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00004_4_hidden=496,lr=0.0720,momentum=0.5562_2024-03-04_04-07-47/checkpoint_000003)\n",
      "\u001b[36m(train_mnist pid=2133)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00003_3_hidden=440,lr=0.0354,momentum=0.4921_2024-03-04_04-07-47/checkpoint_000007)\n",
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00006_6_hidden=429,lr=0.0747,momentum=0.4444_2024-03-04_04-07-47/checkpoint_000002)\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00005_5_hidden=505,lr=0.0388,momentum=0.1234_2024-03-04_04-07-47/checkpoint_000003)\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00004_4_hidden=496,lr=0.0720,momentum=0.5562_2024-03-04_04-07-47/checkpoint_000004)\n",
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00006_6_hidden=429,lr=0.0747,momentum=0.4444_2024-03-04_04-07-47/checkpoint_000003)\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00005_5_hidden=505,lr=0.0388,momentum=0.1234_2024-03-04_04-07-47/checkpoint_000004)\n",
      "\u001b[36m(train_mnist pid=2133)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00003_3_hidden=440,lr=0.0354,momentum=0.4921_2024-03-04_04-07-47/checkpoint_000008)\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00004_4_hidden=496,lr=0.0720,momentum=0.5562_2024-03-04_04-07-47/checkpoint_000005)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Trial status: 3 TERMINATED | 4 RUNNING | 3 PENDING\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Current time: 2024-03-04 04:09:17. Total running time: 1min 30s\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Logical resource usage: 4.0/4 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Current best trial: ceeae_00003 with mean_accuracy=0.9334333539009094 and params={'threads': 2, 'lr': 0.03537662731344751, 'momentum': 0.49206975635349515, 'hidden': 440, 'parent_run_id': 'e836dcb261914663946a937639f9933f'}\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ Trial name                status               lr     momentum     hidden        acc     iter     total time (s) │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00003   RUNNING      0.0353766      0.49207         440   0.933433        9            77.7124 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00004   RUNNING      0.0719952      0.55623         496   0.92595         6            40.7194 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00005   RUNNING      0.0388087      0.123387        505   0.8993          5            36.48   │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00006   RUNNING      0.0747164      0.44443         429   0.905367        4            29.4639 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00000   TERMINATED   0.0986987      0.112969         89   0.912367       12            33.5511 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00001   TERMINATED   0.0351482      0.585167         64   0.9278         12            32.0017 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00002   TERMINATED   0.0474651      0.123255         91   0.914867       12            39.5255 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00007   PENDING      0.017199       0.513358        484                                        │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00008   PENDING      0.0109866      0.126216        141                                        │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00009   PENDING      0.00986737     0.645657         83                                        │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00006_6_hidden=429,lr=0.0747,momentum=0.4444_2024-03-04_04-07-47/checkpoint_000004)\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00005_5_hidden=505,lr=0.0388,momentum=0.1234_2024-03-04_04-07-47/checkpoint_000005)\n",
      "\u001b[36m(train_mnist pid=2133)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00003_3_hidden=440,lr=0.0354,momentum=0.4921_2024-03-04_04-07-47/checkpoint_000009)\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00004_4_hidden=496,lr=0.0720,momentum=0.5562_2024-03-04_04-07-47/checkpoint_000006)\n",
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00006_6_hidden=429,lr=0.0747,momentum=0.4444_2024-03-04_04-07-47/checkpoint_000005)\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00005_5_hidden=505,lr=0.0388,momentum=0.1234_2024-03-04_04-07-47/checkpoint_000006)\n",
      "\u001b[36m(train_mnist pid=2133)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00003_3_hidden=440,lr=0.0354,momentum=0.4921_2024-03-04_04-07-47/checkpoint_000010)\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00004_4_hidden=496,lr=0.0720,momentum=0.5562_2024-03-04_04-07-47/checkpoint_000007)\n",
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00006_6_hidden=429,lr=0.0747,momentum=0.4444_2024-03-04_04-07-47/checkpoint_000006)\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00005_5_hidden=505,lr=0.0388,momentum=0.1234_2024-03-04_04-07-47/checkpoint_000007)\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00004_4_hidden=496,lr=0.0720,momentum=0.5562_2024-03-04_04-07-47/checkpoint_000008)\n",
      "\u001b[36m(train_mnist pid=2133)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00003_3_hidden=440,lr=0.0354,momentum=0.4921_2024-03-04_04-07-47/checkpoint_000011)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 78ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=2133)\u001b[0m WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00006_6_hidden=429,lr=0.0747,momentum=0.4444_2024-03-04_04-07-47/checkpoint_000007)\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00005_5_hidden=505,lr=0.0388,momentum=0.1234_2024-03-04_04-07-47/checkpoint_000008)\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00004_4_hidden=496,lr=0.0720,momentum=0.5562_2024-03-04_04-07-47/checkpoint_000009)\n",
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00006_6_hidden=429,lr=0.0747,momentum=0.4444_2024-03-04_04-07-47/checkpoint_000008)\n",
      "\u001b[36m(train_mnist pid=2133)\u001b[0m 2024/03/04 04:09:45 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ray/anaconda3/lib/python3.9/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00005_5_hidden=505,lr=0.0388,momentum=0.1234_2024-03-04_04-07-47/checkpoint_000009)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Trial status: 3 TERMINATED | 4 RUNNING | 3 PENDING\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Current time: 2024-03-04 04:09:47. Total running time: 2min 0s\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Logical resource usage: 4.0/4 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Current best trial: ceeae_00003 with mean_accuracy=0.9416833519935608 and params={'threads': 2, 'lr': 0.03537662731344751, 'momentum': 0.49206975635349515, 'hidden': 440, 'parent_run_id': 'e836dcb261914663946a937639f9933f'}\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ Trial name                status               lr     momentum     hidden        acc     iter     total time (s) │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00003   RUNNING      0.0353766      0.49207         440   0.941683       12           101.955  │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00004   RUNNING      0.0719952      0.55623         496   0.939983       10            65.9372 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00005   RUNNING      0.0388087      0.123387        505   0.92155        10            69.9594 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00006   RUNNING      0.0747164      0.44443         429   0.93185         9            62.5016 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00000   TERMINATED   0.0986987      0.112969         89   0.912367       12            33.5511 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00001   TERMINATED   0.0351482      0.585167         64   0.9278         12            32.0017 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00002   TERMINATED   0.0474651      0.123255         91   0.914867       12            39.5255 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00007   PENDING      0.017199       0.513358        484                                        │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00008   PENDING      0.0109866      0.126216        141                                        │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00009   PENDING      0.00986737     0.645657         83                                        │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Trial train_mnist_ceeae_00003 completed after 12 iterations at 2024-03-04 04:09:48. Total running time: 2min 0s\n",
      "\u001b[36m(train_mnist pid=2133)\u001b[0m run_id: 90316abe10ad4c0ab4c88a8c39529fe0; status: RUNNING\n",
      "\u001b[36m(train_mnist pid=2133)\u001b[0m --\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╭────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ Trial train_mnist_ceeae_00003 result                       │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ├────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ checkpoint_dir_name                      checkpoint_000011 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ time_this_iter_s                                   7.97426 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ time_total_s                                     101.95505 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ training_iteration                                      12 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ mean_accuracy                                      0.94168 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╰────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00004_4_hidden=496,lr=0.0720,momentum=0.5562_2024-03-04_04-07-47/checkpoint_000010)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Trial train_mnist_ceeae_00007 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ Trial train_mnist_ceeae_00007 config                          │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ hidden                                                    484 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ lr                                                     0.0172 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ momentum                                              0.51336 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ parent_run_id                            ...3946a937639f9933f │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ threads                                                     2 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=2133)\u001b[0m WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=2133)\u001b[0m Checking for active runs, Active Run= None\n",
      "\u001b[36m(train_mnist pid=2133)\u001b[0m Started new run with run_id: 0ae37f5a7f6c4059aba7fb953be0c535\n",
      "\u001b[36m(train_mnist pid=2133)\u001b[0m {'threads': 2, 'lr': 0.017198991160267567, 'momentum': 0.5133576680229408, 'hidden': 484, 'parent_run_id': 'e836dcb261914663946a937639f9933f'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=2133)\u001b[0m 2024-03-04 04:09:49.304424: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 188160000 exceeds 10% of free system memory.\n",
      "\u001b[36m(train_mnist pid=2133)\u001b[0m WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0050s vs `on_train_batch_end` time: 0.0080s). Check your callbacks.\n",
      "\u001b[36m(train_mnist pid=2133)\u001b[0m WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0050s vs `on_train_batch_end` time: 0.0080s). Check your callbacks.\n",
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00006_6_hidden=429,lr=0.0747,momentum=0.4444_2024-03-04_04-07-47/checkpoint_000009)\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00005_5_hidden=505,lr=0.0388,momentum=0.1234_2024-03-04_04-07-47/checkpoint_000010)\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00004_4_hidden=496,lr=0.0720,momentum=0.5562_2024-03-04_04-07-47/checkpoint_000011)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00006_6_hidden=429,lr=0.0747,momentum=0.4444_2024-03-04_04-07-47/checkpoint_000010)\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00005_5_hidden=505,lr=0.0388,momentum=0.1234_2024-03-04_04-07-47/checkpoint_000011)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
      "\u001b[36m(train_mnist pid=2133)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00007_7_hidden=484,lr=0.0172,momentum=0.5134_2024-03-04_04-07-47/checkpoint_000000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m run_id: bbfdd9371f5344bfae5d55071269fb0b; status: RUNNING\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m --\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Trial train_mnist_ceeae_00004 completed after 12 iterations at 2024-03-04 04:10:02. Total running time: 2min 14s\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╭────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ Trial train_mnist_ceeae_00004 result                       │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ├────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ checkpoint_dir_name                      checkpoint_000011 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ time_this_iter_s                                    6.2086 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ time_total_s                                      78.44456 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ training_iteration                                      12 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ mean_accuracy                                       0.9462 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╰────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Trial train_mnist_ceeae_00008 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ Trial train_mnist_ceeae_00008 config                          │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ hidden                                                    141 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ lr                                                    0.01099 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ momentum                                              0.12622 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ parent_run_id                            ...3946a937639f9933f │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ threads                                                     2 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checking for active runs, Active Run= None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Started new run with run_id: 6b005c1850a842f5bf48d8a77fde5a14\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m {'threads': 2, 'lr': 0.01098656915496414, 'momentum': 0.12621552071911193, 'hidden': 141, 'parent_run_id': 'e836dcb261914663946a937639f9933f'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00006_6_hidden=429,lr=0.0747,momentum=0.4444_2024-03-04_04-07-47/checkpoint_000011)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m run_id: 94e46654ae904f72938b78264bfeaea7; status: RUNNING\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m --\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Trial train_mnist_ceeae_00005 completed after 12 iterations at 2024-03-04 04:10:06. Total running time: 2min 19s\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╭────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ Trial train_mnist_ceeae_00005 result                       │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ├────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ checkpoint_dir_name                      checkpoint_000011 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ time_this_iter_s                                   6.65022 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ time_total_s                                      83.20233 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ training_iteration                                      12 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ mean_accuracy                                      0.92683 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╰────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Trial train_mnist_ceeae_00009 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ Trial train_mnist_ceeae_00009 config                          │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ hidden                                                     83 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ lr                                                    0.00987 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ momentum                                              0.64566 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ parent_run_id                            ...3946a937639f9933f │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ threads                                                     2 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checking for active runs, Active Run= None\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Started new run with run_id: e1c047bcdea74c6a9033243f9b15e497\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m {'threads': 2, 'lr': 0.009867368316286516, 'momentum': 0.6456574697396144, 'hidden': 83, 'parent_run_id': 'e836dcb261914663946a937639f9933f'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
      "\u001b[36m(train_mnist pid=2133)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00007_7_hidden=484,lr=0.0172,momentum=0.5134_2024-03-04_04-07-47/checkpoint_000001)\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00008_8_hidden=141,lr=0.0110,momentum=0.1262_2024-03-04_04-07-47/checkpoint_000000)\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00008_8_hidden=141,lr=0.0110,momentum=0.1262_2024-03-04_04-07-47/checkpoint_000001)\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00009_9_hidden=83,lr=0.0099,momentum=0.6457_2024-03-04_04-07-47/checkpoint_000000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m run_id: 36a82d84abc54ab3a83b26cca59f55c8; status: RUNNING\n",
      "\u001b[36m(train_mnist pid=851, ip=100.64.11.148)\u001b[0m --\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Trial train_mnist_ceeae_00006 completed after 12 iterations at 2024-03-04 04:10:13. Total running time: 2min 26s\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╭────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ Trial train_mnist_ceeae_00006 result                       │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ├────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ checkpoint_dir_name                      checkpoint_000011 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ time_this_iter_s                                   6.71041 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ time_total_s                                      82.29073 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ training_iteration                                      12 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ mean_accuracy                                       0.9388 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╰────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00009_9_hidden=83,lr=0.0099,momentum=0.6457_2024-03-04_04-07-47/checkpoint_000001)\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00008_8_hidden=141,lr=0.0110,momentum=0.1262_2024-03-04_04-07-47/checkpoint_000002)\n",
      "\u001b[36m(train_mnist pid=2133)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00007_7_hidden=484,lr=0.0172,momentum=0.5134_2024-03-04_04-07-47/checkpoint_000002)\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00009_9_hidden=83,lr=0.0099,momentum=0.6457_2024-03-04_04-07-47/checkpoint_000002)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Trial status: 7 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Current time: 2024-03-04 04:10:17. Total running time: 2min 30s\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Logical resource usage: 3.0/4 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Current best trial: ceeae_00004 with mean_accuracy=0.9462000131607056 and params={'threads': 2, 'lr': 0.07199524345173318, 'momentum': 0.5562304366072593, 'hidden': 496, 'parent_run_id': 'e836dcb261914663946a937639f9933f'}\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ Trial name                status               lr     momentum     hidden        acc     iter     total time (s) │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00007   RUNNING      0.017199       0.513358        484   0.9001          3            28.9138 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00008   RUNNING      0.0109866      0.126216        141   0.865667        3            12.7914 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00009   RUNNING      0.00986737     0.645657         83   0.890467        3            10.5146 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00000   TERMINATED   0.0986987      0.112969         89   0.912367       12            33.5511 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00001   TERMINATED   0.0351482      0.585167         64   0.9278         12            32.0017 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00002   TERMINATED   0.0474651      0.123255         91   0.914867       12            39.5255 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00003   TERMINATED   0.0353766      0.49207         440   0.941683       12           101.955  │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00004   TERMINATED   0.0719952      0.55623         496   0.9462         12            78.4446 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00005   TERMINATED   0.0388087      0.123387        505   0.926833       12            83.2023 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00006   TERMINATED   0.0747164      0.44443         429   0.9388         12            82.2907 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00008_8_hidden=141,lr=0.0110,momentum=0.1262_2024-03-04_04-07-47/checkpoint_000003)\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00009_9_hidden=83,lr=0.0099,momentum=0.6457_2024-03-04_04-07-47/checkpoint_000003)\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00008_8_hidden=141,lr=0.0110,momentum=0.1262_2024-03-04_04-07-47/checkpoint_000004)\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00009_9_hidden=83,lr=0.0099,momentum=0.6457_2024-03-04_04-07-47/checkpoint_000004)\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00008_8_hidden=141,lr=0.0110,momentum=0.1262_2024-03-04_04-07-47/checkpoint_000005)\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00009_9_hidden=83,lr=0.0099,momentum=0.6457_2024-03-04_04-07-47/checkpoint_000005)\n",
      "\u001b[36m(train_mnist pid=2133)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00007_7_hidden=484,lr=0.0172,momentum=0.5134_2024-03-04_04-07-47/checkpoint_000003)\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00009_9_hidden=83,lr=0.0099,momentum=0.6457_2024-03-04_04-07-47/checkpoint_000006)\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00008_8_hidden=141,lr=0.0110,momentum=0.1262_2024-03-04_04-07-47/checkpoint_000006)\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00009_9_hidden=83,lr=0.0099,momentum=0.6457_2024-03-04_04-07-47/checkpoint_000007)\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00008_8_hidden=141,lr=0.0110,momentum=0.1262_2024-03-04_04-07-47/checkpoint_000007)\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00009_9_hidden=83,lr=0.0099,momentum=0.6457_2024-03-04_04-07-47/checkpoint_000008)\n",
      "\u001b[36m(train_mnist pid=2133)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00007_7_hidden=484,lr=0.0172,momentum=0.5134_2024-03-04_04-07-47/checkpoint_000004)\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00008_8_hidden=141,lr=0.0110,momentum=0.1262_2024-03-04_04-07-47/checkpoint_000008)\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00009_9_hidden=83,lr=0.0099,momentum=0.6457_2024-03-04_04-07-47/checkpoint_000009)\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00009_9_hidden=83,lr=0.0099,momentum=0.6457_2024-03-04_04-07-47/checkpoint_000010)\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00008_8_hidden=141,lr=0.0110,momentum=0.1262_2024-03-04_04-07-47/checkpoint_000009)\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00009_9_hidden=83,lr=0.0099,momentum=0.6457_2024-03-04_04-07-47/checkpoint_000011)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00008_8_hidden=141,lr=0.0110,momentum=0.1262_2024-03-04_04-07-47/checkpoint_000010)\n",
      "\u001b[36m(train_mnist pid=2133)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00007_7_hidden=484,lr=0.0172,momentum=0.5134_2024-03-04_04-07-47/checkpoint_000005)\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00008_8_hidden=141,lr=0.0110,momentum=0.1262_2024-03-04_04-07-47/checkpoint_000011)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Trial status: 7 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Current time: 2024-03-04 04:10:47. Total running time: 3min 0s\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Logical resource usage: 3.0/4 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Current best trial: ceeae_00004 with mean_accuracy=0.9462000131607056 and params={'threads': 2, 'lr': 0.07199524345173318, 'momentum': 0.5562304366072593, 'hidden': 496, 'parent_run_id': 'e836dcb261914663946a937639f9933f'}\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ Trial name                status               lr     momentum     hidden        acc     iter     total time (s) │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00007   RUNNING      0.017199       0.513358        484   0.922267        6            53.4278 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00008   RUNNING      0.0109866      0.126216        141   0.919483       12            41.9762 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00009   RUNNING      0.00986737     0.645657         83   0.938217       12            33.1493 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00000   TERMINATED   0.0986987      0.112969         89   0.912367       12            33.5511 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00001   TERMINATED   0.0351482      0.585167         64   0.9278         12            32.0017 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00002   TERMINATED   0.0474651      0.123255         91   0.914867       12            39.5255 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00003   TERMINATED   0.0353766      0.49207         440   0.941683       12           101.955  │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00004   TERMINATED   0.0719952      0.55623         496   0.9462         12            78.4446 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00005   TERMINATED   0.0388087      0.123387        505   0.926833       12            83.2023 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00006   TERMINATED   0.0747164      0.44443         429   0.9388         12            82.2907 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Trial train_mnist_ceeae_00009 completed after 12 iterations at 2024-03-04 04:10:49. Total running time: 3min 1s\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╭────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ Trial train_mnist_ceeae_00009 result                       │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ├────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ checkpoint_dir_name                      checkpoint_000011 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ time_this_iter_s                                   2.53712 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ time_total_s                                      33.14929 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ training_iteration                                      12 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ mean_accuracy                                      0.93822 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╰────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m run_id: e1c047bcdea74c6a9033243f9b15e497; status: RUNNING\n",
      "\u001b[36m(train_mnist pid=744, ip=100.64.7.88)\u001b[0m --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=2133)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00007_7_hidden=484,lr=0.0172,momentum=0.5134_2024-03-04_04-07-47/checkpoint_000006)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Trial train_mnist_ceeae_00008 completed after 12 iterations at 2024-03-04 04:10:53. Total running time: 3min 6s\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╭────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ Trial train_mnist_ceeae_00008 result                       │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ├────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ checkpoint_dir_name                      checkpoint_000011 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ time_this_iter_s                                   3.20305 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ time_total_s                                      41.97621 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ training_iteration                                      12 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ mean_accuracy                                      0.91948 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╰────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m run_id: 6b005c1850a842f5bf48d8a77fde5a14; status: RUNNING\n",
      "\u001b[36m(train_mnist pid=386, ip=100.64.67.193)\u001b[0m --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=2133)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00007_7_hidden=484,lr=0.0172,momentum=0.5134_2024-03-04_04-07-47/checkpoint_000007)\n",
      "\u001b[36m(train_mnist pid=2133)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00007_7_hidden=484,lr=0.0172,momentum=0.5134_2024-03-04_04-07-47/checkpoint_000008)\n",
      "\u001b[36m(train_mnist pid=2133)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00007_7_hidden=484,lr=0.0172,momentum=0.5134_2024-03-04_04-07-47/checkpoint_000009)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Trial status: 9 TERMINATED | 1 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Current time: 2024-03-04 04:11:18. Total running time: 3min 30s\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Logical resource usage: 1.0/4 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Current best trial: ceeae_00004 with mean_accuracy=0.9462000131607056 and params={'threads': 2, 'lr': 0.07199524345173318, 'momentum': 0.5562304366072593, 'hidden': 496, 'parent_run_id': 'e836dcb261914663946a937639f9933f'}\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ Trial name                status               lr     momentum     hidden        acc     iter     total time (s) │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00007   RUNNING      0.017199       0.513358        484   0.937433       10            86.0739 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00000   TERMINATED   0.0986987      0.112969         89   0.912367       12            33.5511 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00001   TERMINATED   0.0351482      0.585167         64   0.9278         12            32.0017 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00002   TERMINATED   0.0474651      0.123255         91   0.914867       12            39.5255 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00003   TERMINATED   0.0353766      0.49207         440   0.941683       12           101.955  │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00004   TERMINATED   0.0719952      0.55623         496   0.9462         12            78.4446 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00005   TERMINATED   0.0388087      0.123387        505   0.926833       12            83.2023 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00006   TERMINATED   0.0747164      0.44443         429   0.9388         12            82.2907 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00008   TERMINATED   0.0109866      0.126216        141   0.919483       12            41.9762 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00009   TERMINATED   0.00986737     0.645657         83   0.938217       12            33.1493 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=2133)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00007_7_hidden=484,lr=0.0172,momentum=0.5134_2024-03-04_04-07-47/checkpoint_000010)\n",
      "\u001b[36m(train_mnist pid=2133)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/data/mlflow-demos/exp/train_mnist_ceeae_00007_7_hidden=484,lr=0.0172,momentum=0.5134_2024-03-04_04-07-47/checkpoint_000011)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=2133)\u001b[0m WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Trial train_mnist_ceeae_00007 completed after 12 iterations at 2024-03-04 04:11:39. Total running time: 3min 51s\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╭────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ Trial train_mnist_ceeae_00007 result                       │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ├────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ checkpoint_dir_name                      checkpoint_000011 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ time_this_iter_s                                   8.17365 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ time_total_s                                      102.3853 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ training_iteration                                      12 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ mean_accuracy                                      0.94323 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╰────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(train_mnist pid=2133)\u001b[0m run_id: 0ae37f5a7f6c4059aba7fb953be0c535; status: RUNNING\n",
      "\u001b[36m(train_mnist pid=2133)\u001b[0m --\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Trial status: 10 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Current time: 2024-03-04 04:11:39. Total running time: 3min 52s\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Logical resource usage: 1.0/4 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m Current best trial: ceeae_00004 with mean_accuracy=0.9462000131607056 and params={'threads': 2, 'lr': 0.07199524345173318, 'momentum': 0.5562304366072593, 'hidden': 496, 'parent_run_id': 'e836dcb261914663946a937639f9933f'}\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ Trial name                status               lr     momentum     hidden        acc     iter     total time (s) │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00000   TERMINATED   0.0986987      0.112969         89   0.912367       12            33.5511 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00001   TERMINATED   0.0351482      0.585167         64   0.9278         12            32.0017 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00002   TERMINATED   0.0474651      0.123255         91   0.914867       12            39.5255 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00003   TERMINATED   0.0353766      0.49207         440   0.941683       12           101.955  │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00004   TERMINATED   0.0719952      0.55623         496   0.9462         12            78.4446 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00005   TERMINATED   0.0388087      0.123387        505   0.926833       12            83.2023 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00006   TERMINATED   0.0747164      0.44443         429   0.9388         12            82.2907 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00007   TERMINATED   0.017199       0.513358        484   0.943233       12           102.385  │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00008   TERMINATED   0.0109866      0.126216        141   0.919483       12            41.9762 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m │ train_mnist_ceeae_00009   TERMINATED   0.00986737     0.645657         83   0.938217       12            33.1493 │\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1977)\u001b[0m \n",
      "Best hyperparameters found were:  {'threads': 2, 'lr': 0.07199524345173318, 'momentum': 0.5562304366072593, 'hidden': 496, 'parent_run_id': 'e836dcb261914663946a937639f9933f'}\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    parent_run_id = run.info.run_id\n",
    "    print(parent_run_id)\n",
    "    tune_mnist(parent_run_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec33309-6502-4a99-aae2-9eec73673e29",
   "metadata": {
    "tags": []
   },
   "source": [
    "What the final output looks like\n",
    "\n",
    "```\n",
    "(TunerInternal pid=1977) Trial status: 10 TERMINATED\n",
    "(TunerInternal pid=1977) Current time: 2024-03-04 04:11:39. Total running time: 3min 52s\n",
    "(TunerInternal pid=1977) Logical resource usage: 1.0/4 CPUs, 0/0 GPUs\n",
    "(TunerInternal pid=1977) Current best trial: ceeae_00004 with mean_accuracy=0.9462000131607056 and params={'threads': 2, 'lr': 0.07199524345173318, 'momentum': 0.5562304366072593, 'hidden': 496, 'parent_run_id': 'e836dcb261914663946a937639f9933f'}\n",
    "(TunerInternal pid=1977) ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
    "(TunerInternal pid=1977) │ Trial name                status               lr     momentum     hidden        acc     iter     total time (s) │\n",
    "(TunerInternal pid=1977) ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
    "(TunerInternal pid=1977) │ train_mnist_ceeae_00000   TERMINATED   0.0986987      0.112969         89   0.912367       12            33.5511 │\n",
    "(TunerInternal pid=1977) │ train_mnist_ceeae_00001   TERMINATED   0.0351482      0.585167         64   0.9278         12            32.0017 │\n",
    "(TunerInternal pid=1977) │ train_mnist_ceeae_00002   TERMINATED   0.0474651      0.123255         91   0.914867       12            39.5255 │\n",
    "(TunerInternal pid=1977) │ train_mnist_ceeae_00003   TERMINATED   0.0353766      0.49207         440   0.941683       12           101.955  │\n",
    "(TunerInternal pid=1977) │ train_mnist_ceeae_00004   TERMINATED   0.0719952      0.55623         496   0.9462         12            78.4446 │\n",
    "(TunerInternal pid=1977) │ train_mnist_ceeae_00005   TERMINATED   0.0388087      0.123387        505   0.926833       12            83.2023 │\n",
    "(TunerInternal pid=1977) │ train_mnist_ceeae_00006   TERMINATED   0.0747164      0.44443         429   0.9388         12            82.2907 │\n",
    "(TunerInternal pid=1977) │ train_mnist_ceeae_00007   TERMINATED   0.017199       0.513358        484   0.943233       12           102.385  │\n",
    "(TunerInternal pid=1977) │ train_mnist_ceeae_00008   TERMINATED   0.0109866      0.126216        141   0.919483       12            41.9762 │\n",
    "(TunerInternal pid=1977) │ train_mnist_ceeae_00009   TERMINATED   0.00986737     0.645657         83   0.938217       12            33.1493 │\n",
    "(TunerInternal pid=1977) ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
    "(TunerInternal pid=1977) \n",
    "Best hyperparameters found were:  {'threads': 2, 'lr': 0.07199524345173318, 'momentum': 0.5562304366072593, 'hidden': 496, 'parent_run_id': 'e836dcb261914663946a937639f9933f'}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12954385-aa8e-4892-a9d4-226e6603c00e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c544e15c-6a09-4915-b576-9462ac6b9ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "dca-init": "true",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
